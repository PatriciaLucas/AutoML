# -*- coding: utf-8 -*-
"""
Created on Mon Aug 21 07:58:04 2023

@author: Patricia
"""
from MARTS import util

import pandas as pd
import numpy as np
from tigramite.pcmci import PCMCI
from tigramite import data_processing as pp
from tigramite.independence_tests.parcorr import ParCorr
from stationarizer import simple_auto_stationarize
from statsmodels.regression.linear_model import OLS
from statsmodels.tools import add_constant

import warnings
warnings.filterwarnings("ignore")

def organize_graph(G, var_names, target):
    """

    Parameters
    ----------
    G : Numpy array
        Graph generated by PCMCI.
    var_names : list
        List of dataset variables.
    target : string
        Endogenous variable name.

    Returns
    -------
    Pandas dataframe
        Organized G graph.

    """
    new_G = pd.DataFrame(columns=list(range(0,G.shape[2])))
    id_target = var_names.index(target)
    len_var_names = len(var_names)
    for var in range(len_var_names):
        new_G.loc[var] = list(G[var][id_target] == "-->")
    new_G.index = var_names
    return new_G.T.iloc[1:]

def causal_graph(dataset, target, max_lags):
    """
    

    Parameters
    ----------
    dataset : Pandas dataframe
        Input data. Univariate or multivariate time series.
    alpha_level : float
        Significance level of the PC method.
    target : string
        Endogenous variable name.
    max_lags : int
        Maximum lags used by PCMCI.

    Returns
    -------
    G_list : list
        List of graphs of all dataset variables.

    """
    
    dataset = simple_auto_stationarize(dataset)
    
    var_names = list(dataset.columns.values)
    
    len_var_names = len(var_names)
    for var in range(len_var_names):
        if var == 0:
            data = dataset[var_names[var]].values.reshape((-1,1))
        else:
            if len(var_names) > 1:
                data = np.concatenate((data,dataset[var_names[var]].values.reshape((-1,1))), axis=1)
            else:
                break

    dataframe = pp.DataFrame(data, datatime = {0:np.arange(len(dataset))}, var_names=var_names)

    pcmci = PCMCI(dataframe=dataframe, cond_ind_test = ParCorr(significance='analytic'), verbosity=0)
    results = pcmci.run_pcmci(tau_max=max_lags, pc_alpha=0.1, alpha_level=0.01)
    q_matrix = pcmci.get_corrected_pvalues(p_matrix=results['p_matrix'], tau_max=max_lags, fdr_method='fdr_bh')
    G = pcmci.get_graph_from_pmatrix(p_matrix=q_matrix, alpha_level=0.01, tau_min=0, tau_max=max_lags)
    G_list = dict.fromkeys(list(var_names), {})
    
    
    l = []
    for var in G_list:
        G_list[var] = organize_graph(G, var_names, var)

        if target == "":
            if "IMF" not in var:         
                cols_to_drop = G_list[var].columns[G_list[var].columns.str.contains('IMF')]
                G_list[var].drop(cols_to_drop, axis=1, inplace=True)
        else:
            if var != target and "IMF" not in var:
                G_list[var].pop(target)

        if np.all(G_list[var] == False):
            l.append(var)



    set_l = set(l)
    set_G_list = set(G_list)
    set_intersection = set_l.intersection(set_G_list)
    for k in set_intersection:
        del G_list[k]
    
    for var in G_list:
        set_G_list_var = set(G_list[var])
        set_intersection = set_l.intersection(set_G_list_var)
        for k in set_intersection:
            del G_list[var][k]
    
    l = []
    check = True
    while check:
        for var in G_list:
            if np.all(G_list[var] == False):
                l.append(var)
        
        if not l:
            check = False
        
        set_l = set(l)
        set_G_list = set(G_list)
        set_intersection = set_l.intersection(set_G_list)
        for k in set_intersection:
            del G_list[k]
        
        for var in G_list:
            set_G_list_var = set(G_list[var])
            set_intersection = set_l.intersection(set_G_list_var)
            for k in set_intersection:
                del G_list[var][k]
            
        
    return G_list


    
def optimize_max_lags(dataset,target):
    """

    Parameters
    ----------
    g : dataframe
        Univariate graph of a database variable.
    num_samples : int
       Number of samples.

    Returns
    -------
    samples : list
    Sample list for a database variable.

    """
    akaike = []
    lags = [5,10,15,20]
    
    for max_lags in lags:
        G_list = complete_graph(dataset, target, max_lags)
        dict_dataset = util.get_datasets(dataset, G_list, max_lags, target)
        regr = OLS(np.array(dict_dataset['y_train'], dtype=float), 
                   add_constant(np.array(dict_dataset['y_train']))).fit()
        if len(akaike) != 0:
            if regr.aic < akaike[-1]:
                akaike.append(regr.aic)
            else:
                break
        else:
            akaike.append(regr.aic)

    return lags[akaike.index(min(akaike))]



def complete_graph(dataset, target, max_lags):

    G_list = dict.fromkeys(list(dataset.columns.values), {})
    
    for var in G_list:
        G = pd.DataFrame(True, index = np.arange(0,max_lags+1), columns = dataset.columns.values)
        if var != target: del G[target]
        G_list[var] = G.iloc[1:]

    return G_list
    






















import pandas as pd
import numpy as np
from tigramite.pcmci import PCMCI
from tigramite import data_processing as pp
from tigramite.independence_tests.parcorr import ParCorr
from stationarizer import simple_auto_stationarize
from statsmodels.regression.linear_model import OLS
from statsmodels.tools import add_constant
import CATS.organization as org
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings("ignore")

def organize_graph(G, var_names, target):
    """

    Parameters
    ----------
    G : Numpy array
        Graph generated by PCMCI.
    var_names : list
        List of dataset variables.
    target : string
        Endogenous variable name.

    Returns
    -------
    Pandas dataframe
        Organized G graph.

    """
    new_G = pd.DataFrame(columns=list(range(0,G.shape[2])))
    id_target = var_names.index(target)
    for var in range(len(var_names)):
        new_G.loc[var] = list(G[var][id_target] == "-->")
    new_G.index = var_names
    return new_G.T.iloc[1:]

def causal_graph(dataset, target, max_lags):
    """
    

    Parameters
    ----------
    dataset : Pandas dataframe
        Input data. Univariate or multivariate time series.
    alpha_level : float
        Significance level of the PC method.
    target : string
        Endogenous variable name.
    max_lags : int
        Maximum lags used by PCMCI.

    Returns
    -------
    G_list : list
        List of graphs of all dataset variables.

    """
    
    dataset = simple_auto_stationarize(dataset)
    
    var_names = list(dataset.columns.values)
    
    for var in range(len(var_names)):
        if var == 0:
            data = dataset[var_names[var]].values.reshape((-1,1))
        else:
            if len(var_names) > 1:
                data = np.concatenate((data,dataset[var_names[var]].values.reshape((-1,1))), axis=1)
            else:
                break

    dataframe = pp.DataFrame(data, datatime = {0:np.arange(len(dataset))}, var_names=var_names)

    pcmci = PCMCI(dataframe=dataframe, cond_ind_test = ParCorr(significance='analytic'), verbosity=0)
    results = pcmci.run_pcmci(tau_max=max_lags, pc_alpha=0.1, alpha_level=0.01)
    q_matrix = pcmci.get_corrected_pvalues(p_matrix=results['p_matrix'], tau_max=max_lags, fdr_method='fdr_bh')
    G = pcmci.get_graph_from_pmatrix(p_matrix=q_matrix, alpha_level=0.01, tau_min=0, tau_max=max_lags)
    G_list = dict.fromkeys(list(var_names), {})
    l = []
    for var in G_list:
        G_list[var] = organize_graph(G, var_names, var)
        if var != target[0]: G_list[var].pop(target[0])
        if np.all(G_list[var] == False):
            l.append(var)

    for k in l:
        G_list.pop(k)

    for var in G_list:
        for k in l:
            G_list[var].pop(k)
    
    return G_list


def optimize_max_lags(dataset,target):
    """

    Parameters
    ----------
    g : dataframe
        Univariate graph of a database variable.
    num_samples : int
       Number of samples.

    Returns
    -------
    samples : list
    Sample list for a database variable.

    """
    akaike = []
    lags = [5,10,15,20,25,30,35,40]
    for max_lags in lags:
        G_list = causal_graph(dataset, [target], max_lags)
        dict_dataset = org.get_datasets(dataset, G_list, max_lags, target)
        regr = OLS(np.array(dict_dataset['y'], dtype=float), 
                   add_constant(np.array(dict_dataset['y']))).fit()
        if len(akaike) != 0:
            if regr.aic < akaike[-1]:
                akaike.append(regr.aic)
            else:
                break
        else:
            akaike.append(regr.aic)

    return lags[akaike.index(min(akaike))]














